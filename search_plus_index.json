{"./":{"url":"./","title":"译者序","keywords":"","body":"Knative入门——构建基于 Kubernetes 的现代化Serverless应用 本书是 Getting Started with Knative - Building Modern Serverless Workloads on Kubernetes 的中文版，由 ServiceMesher 社区翻译。 关于本书 Getting Started with Knative 是一本由 Pivotal 公司赞助 O’Reilly 出品的免费电子书，英文版下载地址：https://content.pivotal.io/ebooks/getting-started-with-knative。 在线阅读：https://www.servicemesher.com/getting-started-with-knative/ Github：https://github.com/servicemesher/getting-started-with-knative/ 关于 Knative Knative 是一个基于 Kubernetes 的，用于构建、部署和管理现代 serverless 应用的平台。 关于 ServiceMesher 社区 ServiceMesher社区，关注内容涵盖Kubernetes、Service Mesh、Istio、Serverless、Knative等云原生技术，社区分享开源技术干货，推动服务网格和云原生在企业的落地。 译者名单 感谢参与本书翻译和审校的所有贡献者（按字母顺序排序）： SataQiu：邱世达 andyyin：殷琦 dishuihengxin：韦世滴 dreadbird：王刚 eportzxp：张晓鹏 fleeto：崔秀龙 haiker2011：孙海洲 icyxp：徐鹏 jordanchenCN：陈佳栋 junahan：杨铁党 lou-lan：翟怀楼 loverto：殷龙飞 mathlsj：李寿景 rootsongjc：宋净超 shaobai：陈冬 各章节详细译者信息 章节 译者 审校者 前言 宋净超 孙海洲，徐鹏 Knative 概述 陈佳栋 宋净超，孙海洲，徐鹏，邱世达，陈冬 Serving（服务） 杨铁党 孙海洲，邱世达，宋净超，徐鹏 Build（构建） 孙海洲 邱世达，陈冬，杨铁党，宋净超，翟怀楼 Eventing（事件） 韦世滴 孙海洲，邱世达，王刚，周雨青，宋净超 Knative 安装 李寿景 邱世达，孙海洲，徐鹏 Knative 使用 殷龙飞 孙海洲，邱世达，王刚，宋净超 演练 张晓鹏 孙海洲，邱世达，宋净超 下一步 殷琦 邱世达，孙海洲 反馈与参与本书 关于本书有任何问题可以提交 Issue 反馈，参与本书翻译请参阅规范。 版权 本书经 Pivotal 公司授权 ServiceMesher 社区翻译，请勿擅自印刷出版，引用本书中文版中的内容请注明出处。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-10-21 14:49:30 "},"preface.html":{"url":"preface.html","title":"前言","summary":"本章是全书的前言，用于说明本书的成因、划定目标读者、致谢等。","keywords":"","body":"前言 Kubernetes 赢了。这不是夸大其词，事实就是如此。越来越多的人开始基于容器部署，而 Kubernetes 已经成为容器编排的事实标准。但是，Kubernetes 自己也承认，它是一个容器平台而不是代码平台。它可以作为一个运行和管理容器的很好的平台，但是这些容器是如何构建、运行、扩展和路由很大程度上是由用户自己决定的。这些是 Knative 想要补充的缺失部分。 也许您已经在生产上使用 Kubernetes，或者您是一个前沿技术爱好者，梦想着将您基于 OS/2 运行的组织现代化。不管怎样，本报告都没有假定太多东西，只是要求您知道容器是什么，具有 Kubernetes 的一些基本知识，可以访问 Kubernetes 集群。如果这些您都不具备的话，那么 Minikube 是一个很好的选择。 我们将使用大量代码示例和预先构建的容器镜像，这些镜像我们都为读者开源，您可以从 http://github.com/gswk 找到所有代码示例，并在 http://hub.docker.com/u/gswk 找到所有容器镜像。您还可以在 http://gswkbook.com 找到这两个存储库以及其他重要参考资料的链接。 我们对 Knative 的未来十分期待。虽然我们来自 Pivotal——Knative 最大的贡献者之—— 但本报告仅出自于对 Knative 的发展前景充满期待的我们。报告中包含了我们的观点，有的读者可能不认同这些观点，还可能会热情地告诉我们为什么我们错了。没关系！这个领域非常新，并且不断重新定义自己。至少，本报告将让您思考无服务器架构（serverless），您会和我们一样对 Knative 感到兴奋。 目标读者 我们本质上是开发人员，所以这份报告主要是针对开发人员编写的。在整个报告中，我们将探索 serverless 架构模式，并向开发人员展示自服务用例示例（例如构建和部署代码）。然而，Knative 吸引了不同角色的技术人员。特别是，将 Knative 组件作为更大平台的一部分或与他们的系统集成的想法会引起运维和平台构建者们的极大兴趣。当这些受众探索如何使用 Knative 来实现其特定目的时，本报告将对他们非常有用。 您将学到什么 尽管本报告并不旨在详解 Knative 的全部功能，但已足够深入，可以带您入门 Knative，了解它的工作原理和使用方式。初步了解了 Knative 后，我们将花一些时间研究如何使用它的每个主要组件。然后转到一些高级用例，最后通过构建一个真实的示例应用来结束，该应用将充分利用您在本报告中学到的所有知识。 致谢 我们要感谢 Pivotal。我们都是第一次合作写书，如果没有 Pivotal 团队的支持，可能就不会有本书。技术营销总监 Dan Baskette（我们的老板）和产品营销副总裁 Richard Seroter 在 Pivotal 和领导者的成长中发挥了重要作用。我们要感谢 Jared Ruckle、Derrick Harris 和 Jeff Kelly，他们给予我们很多帮助。我们还要感谢 Tevin Rawls，他是 Pivotal 团队的一名优秀实习生，帮助我们在第 7 章中为我们的演示构建了前端。当然，我们要感谢 O’Reilly 团队所有人的支持和指导。非常感谢整个 Knative 社区，尤其是那些在 Pivotal 帮助我们的人。最后我们要感谢 Virginia Wilson、Nic Williams 博士、Mark Fisher、Nate Schutta、Michael Kehoe 和 Andrew Martin 花时间审阅我们的稿件。 Brian McClain：我要感谢我的妻子 Sarah 在我写作过程中给予我不断的支持和鼓励。我还要感谢我们的两只狗，Tony 和 Brutus，让我几乎把所有时间都用在这份报告上。还要感谢我们的三只猫 Tyson、Marty 和 Doc，它们有时候会趴在我的笔记本电脑上呼呼大睡，这让我可以更积极地投入写作，感谢它们的陪伴。最后，感谢我的合著者 Bryan Friedman，没有他，我是不可能完成这份报告的。Pivotal 告诉我，合作是 1+1 大于 2。 Bryan Friedman：感谢我的妻子 Alison，她十分支持我的写作，还是我们家最有才华的作家。我还要感谢我两个漂亮的女儿，Madelyn 和 Arielle，她们让我每天都变得更好。我也有一个忠诚的办公室伙伴，我的狗 Princeton，它大多只是喜欢待在沙发上，但偶尔会看着我的脸，暗示他为我在这份报告上的工作感到自豪。当然，我无法独自完成这一切，所以我要感谢我的合著者 Brian McClain，他的技术实力和富有感染力的激情在整个过程中给了我极大的帮助。与他合作真是太荣幸了。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-05-13 14:43:49 "},"knative-overview.html":{"url":"knative-overview.html","title":"Knative 概述","summary":"本章是全书的第一章，主要用来介绍 Knative。","keywords":"","body":"Knative 概述 我们有一个信念：以平台的方式提供软件是一个最佳选择。事实证明，标准化的开发和部署流程能让开发人员更专注于新功能的研发，从而减少时间和金钱上的消耗。不仅如此，确保应用程序之间的一致性也意味着其更容易打补丁、更新和监控，从而让运维工作也更加高效。Knative 的目标就是成为这样的现代化平台。 Knative 是什么？ 我们先来看看 Knative 的目标。Knative 的目标是在基于 Kubernetes 之上为整个开发生命周期提供帮助。它的具体实现方式是：首先使你作为开发人员能够以你想要的语言和以你想要的方式来编写代码，其次帮助你构建和打包应用程序，最后帮助你运行和伸缩应用程序。 为此，Knative 将重点放在三个关键组件上：build（构建）你的应用程序，为其提供流量 serving（服务），以及确保应用程序能够轻松地生产和消费 event（事件）。 Build（构建） 通过灵活的插件化的构建系统将用户源代码构建成容器。目前已经支持多个构建系统，比如 Google 的 Kaniko，它无需运行 Docker daemon 就可以在 Kubernetes 集群上构建容器镜像。 Serving（服务） 基于负载自动伸缩，包括在没有负载时缩减到零。允许你为多个修订版本（revision）应用创建流量策略，从而能够通过 URL 轻松路由到目标应用程序。 Event（事件） 使得生产和消费事件变得容易。抽象出事件源，并允许操作人员使用自己选择的消息传递层。 Knative 是以 Kubernetes 的一组自定义资源类型（CRD）的方式来安装的，因此只需使用几个 YAML 文件就可以轻松地开始使用 Knative 了。这也意味着，在本地或者托管云服务上，任何可以运行 Kubernetes 的地方都可以运行 Knative 和你的代码。 Kubernetes 知识 由于 Knative 是基于 Kubernetes 的一系列扩展，因此建议你先了解下 Kubernetes 和 Docker 的架构和术语。今后我们会提及以下术语，比如 namespace、Deployment、ReplicaSet 和 Pod。熟悉这些 Kubernetes 术语将帮助你在阅读时更好地理解 Knative 的基本工作。如果你对这些都不熟悉，那么这两个链接：Kubernetes 和 Docker 上都有很棒的培训材料，可以直接在浏览器上阅读。 无服务器架构（serverless）？ 到目前为止，我们已经讨论了应用程序的容器化。但都 2019 年了，我们读了半章却还没有提到“无服务器架构（serverless）”这个词。也许作为当今技术中被提到最多的一个词，无服务器架构（serverless）仍然在寻找一个整个行业都能认同的定义。许多人都同意这个理念的影响最大的是代码量，比如以前需要编写大型、单一的应用程序，现在你只需编写通过事件来调用的小型、单一用途的函数即可。这些事件可以简单到是一个 HTTP 请求或一个来自消息通道（如 Apache Kafka）的消息。同时事件也可能是间接的，比如这些操作：将图片上传到 Google Cloud Storage 或更新了 Amazon 的 DynamoDB 中的一张表。 许多人也都同意这表示着你的代码只有在处理请求时才用到计算资源。对于很多托管服务来说，如 Amazon 的 Lambda 或 Google Cloud Functions，这意味着你只需要为活跃期间的计算服务付费，而不是一台 7x24 小时运行并可能在大部分时间内无所事事的虚拟机。在本地或非托管的无服务器架构（serverless）平台上，则表示代码可以只在需要时运行，在不需要时就停止，从而让你的基础设施能在其他方面自由使用计算资源。 在这些基础原理之上的是一场圣战。有些人坚持无服务器架构（serverless）只适合在托管的云环境中运行，在本地运行这样的平台完全是不对的。其他人则认为它更像是一种哲学理论上的设计。也许这些定义最后会合并，也许不会。就目前来说，随着无服务器架构（serverless）普及率的持续增长，Knative 最有可能成为其标准。 为什么是 Knative ？ 除了关于无服务器架构（serverless）定义的争论之外，下一个逻辑问题是“为什么创造的是 Knative ？”随着基于容器的架构的流行和 Kubernetes 的普及，我们又开始见到一些相同的问题，这些问题之前也出现在平台即服务（PaaS）方案上并推动了其发展。如在构建容器时，我们该如何保证其一致性？谁负责给所有东西打补丁？如何根据需求来伸缩？如何实现零停机部署？ 虽然 Kubernetes 确实已经演进并开始解决其中一些问题，但是之前提到的关于不断发展的无服务器架构（serverless）的概念方面产生了更多的问题。如何管理多个事件类型的一致性？如何定义事件源和目标？ 许多无服务器架构（serverless）或函数即服务（FaaS）框架都尝试回答这些问题，但它们都在用不同的方式来解决问题，且不是所有的解决方案都用到了 Kubernetes。而 Knative 构建在 Kubernetes 的基础上，并为构建和部署无服务器架构（serverless）和基于事件驱动的应用程序提供了一致的标准模式。Knative 减少了这种新的软件开发方法所产生的开销，同时还把路由（routing）和事件（eventing）的复杂性抽象出来。 结论 现在我们已经很好地理解了 Knative 是什么以及它被创造出来的原因，接下来我们将进一步深入了解它。接下来的章节将介绍 Knative 的三个关键组件。我们将详细研究它们，并解释它们是如何协同工作的，以及如何充分发挥它们的潜力。之后，我们将了解如何在 Kubernetes 集群上安装 Knative 和一些更高级的用例。最后，我们将通过一个 demo 来展示在这个报告中你能学习到的大部分内容。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-10-21 14:18:04 "},"serving.html":{"url":"serving.html","title":"Serving（服务）","summary":"本章介绍 Knative Serving 组件，描述 Knative Serving 如何部署并为应用和函数 (funtions) 提供服务。","keywords":"","body":"Serving（服务） 即便使用无服务器架构，处理和响应 HTTP 请求的能力依然重要。在开始写代码使用事件触发一个函数之前，您需要有地方来运行代码。 本章探讨 Knative Serving 组件，您将了解 Knative Serving 如何管理部署以及为应用和函数提供服务。通过 Serving，您可以轻松地将一个预先构建好的镜像部署到底层 Kubernetes 集群中。（在第三章： Build，您将看到 如何使用 Knative Build 构建镜像以在 Serving 组件中运行）Knative Serving 维护某一时刻的快照，提供自动化伸缩功能（既支持扩容，也支持缩容直至为零)，以及处理必要的路由和网络编排。 Serving 模块定义一组特定的对象以控制所有功能：Revision（修订版本）、Configuration （配置）、Route（路由）和 Service（服务）。Knative 使用 Kubernetes CRD（自定义资源）的方式实现这些 Kubernetes 对象。下图 2-1 展示所有 Serving 组件对象模型间的关系。在接下去的章节将具体介绍每个部分。 图 2-1: Knative Serving 对象模型 Configuration（配置）和 Revision（修订版本） Knative Serving 始于 Configuration。您可以在 Configuration 中为部署定义所需的状态。最小化 Configuration 至少包括一个配置名称和一个要部署容器镜像的引用。在 Knative 中，定义的引用为 Revision。Revision 代表一个不变的，某一时刻的代码和 Configuration 的快照。每个 Revision 引用一个特定的容器镜像和运行它所需要的任何特定对象（例如环境变量和卷）。然而，您不必显式创建 Revision。由于 Revision 是不变的，它们从不会被改变和删除，相反，当您修改 Configuration 的时候，Knative 会创建一个 Revision。这允许一个 Configuration 既反映工作负载的当前状态，同时也维护一个它自己的历史 Revision 列表。 以下例 2-1 展示了一个完整的 Configuration 定义。它指定一个 Revision，该 Revision 使用一个容器镜像仓库 URI 引用一个特定的镜像并且指定其版本标签。 例 2-1. knative-helloworld/configuration.yml apiVersion: serving.knative.dev/v1alpha1 kind: Configuration metadata: name: knative-helloworld namespace: default spec: revisionTemplate: spec: container: image: docker.io/gswk/knative-helloworld:latest env: - name: MESSAGE value: \"Knative!\" 现在，您可以用一个简单的命令启用该 YAML 文件： $ kubectl apply -f configuration.yaml 自定义端口 默认情况下，Knative 将假定您的应用程序监听 8080 端口。您可以通过 containerPort 参数自定义一个端口： spec: revisionTemplate: spec: container: image: docker.io/gswk/knative-helloworld:latest env: - name: MESSAGE value: \"Knative!\" ports: - containerPort: 8081 就像任意 Kubernetes 对象一样，您可以在系统中使用命令行工具（CLI）查阅 Revision 和 Configuration。您可以使用 kubectl get revisions 和 kubectl get configurations 得到它们的列表。获取我们刚刚创建例 2-1 的 Configuration，可以使用命令 kubectl get configuration knative-helloworld -oyaml。这将以 YAML 形式显示该 Configuration 完整详情（如下例 2-2）。 例 2-2. 命令 kubectl get configuration knative-hellworld -oyaml 的输出 apiVersion: serving.knative.dev/v1alpha1 kind: Configuration metadata: creationTimestamp: YYYY-MM-DDTHH:MM:SSZ generation: 1 labels: serving.knative.dev/route: knative-helloworld serving.knative.dev/service: knative-helloworld name: knative-helloworld namespace: default ownerReferences: - apiVersion: serving.knative.dev/v1alpha1 blockOwnerDeletion: true controller: true kind: Service name: knative-helloworld uid: 9835040f-f29c-11e8-a238-42010a8e0068 resourceVersion: \"374548\" selfLink: \"/apis/serving.knative.dev/v1alpha1/namespaces\\ /default/configurations/knative-helloworld\" uid: 987101a0-f29c-11e8-a238-42010a8e0068 spec: generation: 1 revisionTemplate: metadata: creationTimestamp: null spec: container: image: docker.io/gswk/knative-helloworld:latest name: \"\" resources: {} status: conditions: - lastTransitionTime: YYYY-MM-DDTHH:MM:SSZ status: \"True\" type: Ready latestCreatedRevisionName: knative-helloworld-00001 latestReadyRevisionName: knative-helloworld-00001 observedGeneration: 1 注意例 2-2 中 status 小节，Configuration 控制器保持对最近创建和就绪 Revision 的追踪。它也包含了 Revision 的适用条件，表明它是否就绪以接收流量。 提醒 Configuration 可以指定一个已有的容器镜像，如例 2-1 中所示。或者，它也可以选择指向一个 Build 资源以从源代码创建一个容器镜像。第三章：Build 将介绍 Knative Build 组件的详情并提供一些例。 那么在 Kubernetes 集群内部发生了什么？我们在 Configuration 中指定的容器镜像是什么样子？Knative 转换 Configuration 定义为一些 Kubernetes 对象并在集群中创建它们。在启用 Configuration 后，可以看到相应的 Deployment、ReplicaSet 和 Pod。例 2-3 展示了所有来自例 2-1 所创建的对象。 例 2-3. Knative 创建的 Kubernetes 对象 $ kubectl get deployments -oname deployment.extensions/knative-helloworld-00001-deployment $ kubectl get replicasets -oname replicaset.extensions/knative-helloworld-00001-deployment-5f7b54c768 $ kubectl get pods -oname pod/knative-helloworld-00001-deployment-5f7b54c768-lrqt5 现在我们有了用于运行我们应用的 Pod，但是我们怎么知道该向哪里发送请求？这正是 Route 用武之地。 Route（路由） Knative 中的 Route 提供了一种将流量路由到正在运行的代码的机制。它将一个命名的，HTTP 可寻址端点映射到一个或者多个 Revision。Configuration 本身并不定义 Route。例 2-4 展示了一个将流量发送到指定 Configuration 最新 Revision 的最基本路由定义。 例 2-4. knative-helloworld/route.yml apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-helloworld namespace: default spec: traffic: - configurationName: knative-helloworld percent: 100 就像我们对 Configuration 所做的那样，我们可以运行一个简单的命令应用该 YAML 文件： kubectl apply -f route.yaml 这个定义中，Route 发送 100% 流量到由 configurationName 属性指定 Configuration 的最新就绪 Revision，该 Revision 由 Configuration YAML 中 latestReadyRevisionName 属性定义。您可以通过发送如下 curl 命令来测试这些 Route 和 Configuration ： curl -H \"Host: knative-routing-demo.default.example.com\" http://$KNATIVE_INGRESS 通过使用 revisionName 替代 latestReadyRevisionName ，您可以锁定一个 Route 以发送流量到一个指定的 Revision。使用 name 属性，您也可以通过可寻址子域名访问 Revision。例 2-5 同时展示两种场景。 例 2-5. knative-routing-demo/route.yml apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-routing-demo namespace: default spec: traffic: - revisionName: knative-routing-demo-00001 name: v1 percent: 100 我们可以再一次使用简单命令应用该 YAML 文件： kubectl apply -f route.yaml 指定的 Revision 可以使用 v1 子域名访问，如下 curl 命令所示： curl -H \"Host: v1.knative-routing-demo.default.example.com\" http://$KNATIVE_INGRESS 提醒 Knative 默认使用 example.com 域名，但不适合生产使用。您会注意到在 curl 命令（v1.knative-routing-demo.default.example.com）中作为一个主机头传递的 URL 包含该默认值作为域名后缀。URL 格式遵循模式 {REVISION_NAME}.{SERVICE_NAME}.{NAMESPACE}.{DOMAIN} 。 在这个案例中，子域名中 default 部分指的是命名空间。您将在第六章：部署注意事项一节中学习到如何改变这些值以及如何使用自定义域名。 Knative 也允许以百分比的方式跨 Revision 进行流量分配。支持诸如增量发布、蓝绿部署或者其他复杂的路由场景。您将在第六章看到这些以及其他案例。 Autoscaler（自动伸缩器）和 Activator（激活器） Serverless 的一个关键原则是可以按需扩容以满足需要和缩容以节省资源。Serverless 负载应当可以一直缩容至零。这意味着如果没有请求进入，则不会运行容器实例。Knative 使用两个关键组件以实现该功能。它将 Autoscaler 和 Activator 实现为集群中的 Pod。您可以看到它们伴随其他 Serving 组件一起运行在 knative-serving 命名空间中（参见例 2-6）。 例 2-6. kubectl get pods -n knative-serving 输出 NAME READY STATUS RESTARTS AGE activator-69dc4755b5-p2m5h 2/2 Running 0 7h autoscaler-7645479876-4h2ds 2/2 Running 0 7h controller-545d44d6b5-2s2vt 1/1 Running 0 7h webhook-68fdc88598-qrt52 1/1 Running 0 7h Autoscaler 收集打到 Revision 并发请求数量的有关信息。为了做到这一点，它在 Revision Pod 内运行一个称之为 queue-proxy 的容器，该 Pod 中也运行用户提供的 (user-provided) 镜像。可以在相应 Revision Pod 上，通过运行 kubectl describe 命令可以看到这些容器 (参见例 2-7)。 例 2-7. kubectl describe pod knative-helloworld-00001-deployment-id 输出片段 ... Containers: user-container: Container ID: docker://f02dc... Image: index.docker.io/gswk/knative-helloworld... ... queue-proxy: Container ID: docker://1afcb... Image: gcr.io/knative-releases/github.com/knative... ... queue-proxy 检测该 Revision 上观察到的并发量，然后它每隔一秒将此数据发送到 Autoscaler。Autoscaler 每两秒对这些指标进行评估。基于评估的结果，它增加或者减少 Revision 部署的规模。 默认情况下，Autoscaler 尝试维持每 Pod 每秒平均 100 个并发请求。这些并发目标和平均并发窗口均可以变化。Autoscaler 也能够被配置为利用 Kubernets HPA（Horizontal Pod Autoscaler）来替代该默认配置。这将基于 CPU 使用率来自动伸缩但不支持缩容至零。这些设定都能够通过 Revision 元数据注解（annotations）定制。有关这些注解的详情，请参阅 Knative 文档。 例如，一个 Revision 每秒收到 350 个请求并且每次请求大约需要处理 0.5 秒。使用默认设置（每 Pod 100 个并发请求），这个 Revision 将扩展至两个 Pod： 350 * .5 = 175 175 / 100 = 1.75 ceil(1.75) = 2 pods Autoscaler 也负责缩容至零。Revision 处于 Active（激活）状态才接受请求。当一个 Revision 停止接受请求时，Autoscaler 将其置为 Reserve（待命）状态，条件是每 Pod 平均并发必须持续 30 秒保持为 0（这是默认设置，但可以配置）。 处于 Reserve 状态下，一个 Revision 底层部署缩容至零并且所有到它的流量均路由至 Activator。Activator 是一个共享组件，其捕获所有到待命 Revision 的流量。当它收到一个到某一待命 Revision 的请求后，它转变 Revision 状态至 Active。然后代理请求至合适的 Pod。 Autoscaler 如何伸缩 Autoscaler 采用的伸缩算法针对两个独立的时间间隔计算所有数据点的平均值。它维护两个时间窗，分别是 60 秒和 6 秒。Autoscaler 使用这些数据以两种模式运作：Stable Mode（稳定模式）和 Panic Mode（恐慌模式）。在 Stable 模式下，它使用 60 秒时间窗平均值决定如何伸缩部署以满足期望的并发量。 如果 6 秒窗口的平均并发量两次到达期望目标，Autoscaler 转换为 Panic Mode 并使用 6 秒时间窗。这让它更加快捷的响应瞬间流量的增长。它也仅仅在 Panic Mode 期间扩容以防止 Pod 数量快速波动。如果超过 60 秒没有扩容发生，Autoscaler 会转换回 Stable Mode。 图 2-2 显示 Autoscaler 和 Activator 如何和 Routes 及 Revisions 协同工作。 图 2-2: Autoscaler 和 Activator 如何和 Routes 及 Revisions 互动。 警告 Autoscaler 和 Activator 均是 Knative 中快速演化的部分。参阅最新 Knative 文档获取最近改进。 服务 在 Knative 中，Service 管理工作负载的整个生命周期。包括部署、路由和回滚。（不要将 Knative Service 和 Kubernetes Service 混淆。它们是不同的资源。） Knative Service 控制一系列组成软件的 Route 和 Configuration。Knative Service 可以被看作是一段代码 —— 您正在部署的应用或者函数。 一个 Service 小心确保一个应用有一个 Route、一个 Configuation，以及为每次 Service 更新产生的一个新 Revision。当创建一个 Service 时，您没有特别定义一个 Route，Knative 创建一个发送流量到最新 Revision 的路由。您可以选择一个特定的 Revision 以路由流量到该 Revision。 不要求您明确创建一个 Service。Route 和 Configuration 可以被分开在不同的 YAML 文件（如例 2-1 和 例 2-4）。在这种情形下，您可以应用每个单独的对象到集群。然而，推荐的方式使用一个 Service 来编排 Route 和 Configuration。例 2-8 所示文件用于替换来自例 2-1 和例 2-4 定义的 configuation.yml 和 route.yml。 例 2-8. knative-helloworld/service.yml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: knative-helloworld namespace: default spec: runLatest: configuration: revisionTemplate: spec: container: image: docker.io/gswk/knative-helloworld:latest 注意这个 service.yml 文件和 configuration.yml 非常相似。这个文件定义 Configuration 并且是最小化 Service 定义。由于这里没有 Route 定义，一个默认 Route 指向最新 Revision。Service 控制器整体追踪它所有的 configuration 和 Route 的状态。然后反映这些状态在它的 ConfigurationsReady 和 RoutesReady conditions （工作状况）属性里。当通过 CLI 使用 kubectl get ksvc 命令请求 Knative Service 信息的时候，这些状态可以被看到。 例 2-9. kubectl get ksvc knative-helloworld -oyaml 命令输出片段 apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: ... name: knative-helloworld namespace: default ... spec: ... status: conditions: - lastTransitionTime: YYYY-MM-DDTHH:MM:SSZ status: \"True\" type: ConfigurationsReady - lastTransitionTime: YYYY-MM-DDTHH:MM:SSZ status: \"True\" type: Ready - lastTransitionTime: YYYY-MM-DDTHH:MM:SSZ status: \"True\" type: RoutesReady domain: knative-helloworld.default.example.com domainInternal: knative-helloworld.default.svc.cluster.local latestCreatedRevisionName: knative-helloworld-00001 latestReadyRevisionName: knative-helloworld-00001 observedGeneration: 1 targetable: domainInternal: knative-helloworld.default.svc.cluster.local traffic: - percent: 100 revisionName: knative-helloworld-00001 例 2-9 显示这个命令的输出。 小结 至此已经向您介绍了 Service、Route、Configuration 和 Revision。Revision 是不变的并且只能经由 Configuration 改变而被创建。您可以分别单独创建 Configuration 和 Route，或者把它们组合在一起并定义为一个 Service。理解 Serving 组件的这些构建块是使用 Knative 的基础。您部署的应用均需要一个 Service 或者 Configuration 以在 Knative 中作为容器运行。 但是，如何打包您的源代码进入一个容器镜像以使用本章介绍的方式进行部署？第三章将回答这些问题并且向您介绍 Knative Build 组件。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-10-21 15:27:33 "},"build.html":{"url":"build.html","title":"Build（构建）","summary":"本章是全书的第三章，主要介绍 Build （构建）的几个相关的组件，通过例展示了如何进行配合来减少手动构建，更轻松的完成代码的打包和构建。","keywords":"","body":"Build（构建） Knative 的 Serving（服务）组件是解决如何从容器到 URL 的，而 Build 组件是解决如何从源代码到容器的。Build resource 允许您定义如何编译代码和构建容器，而不是指向预构建的容器镜像。这确保了在将代码发送到容器镜像库之前以一种一致的方式编译和打包代码。本章中将会向您介绍一些新的组件： Build 驱动构建过程的自定义 Kubernetes 资源。在定义构建时，您需要定义如何获取源代码以及如何创建容器镜像来运行代码。 Build Template 封装可重复构建步骤集合以及允许对构建进行参数化的模板。 Service Account 允许对私有资源（如 Git 仓库或容器镜像库）进行身份验证。 [备注] 在撰写本章时，社区正在积极的将 Build 迁移到 Build Pipeline（构建流水线），对 Build 中的流水线进行重构使其更接近 Knative 的 CI/CD 流水线风格。这意味着除了编译和打包代码外，Knative 中的构建还可以轻松地运行测试并发布这些结果。请密切关注 Knative 的未来版本，了解这一变化。 Service Account（服务账户） 在开始配置构建之前会面临一个亟待解决的问题：如何在构建时获得需要验证的服务？如何从私有的 Git 仓库拉取代码或者如何把容器镜像推送到 Docker Hub 中？为此，你可以利用两个 Kubernetes 原生组件的组合：Secret 和 Service Account 。Secret 可以让您安全地存储这些经过身份验证的请求所需的凭据，Service Account 可以让您灵活地为多个构建提供和维护凭据，而无需每次构建新应用程序时手动配置它们。 在例 3-1 中，首先创建一个 Secret ，命名为 dockerhub-account，里面包含需要使用的凭据。当然，可以像应用其他 YAML 一样应用它，如例 3-2 所示。 例 3-1. knative-build-demo/secret.yaml apiVersion: v1 kind: Secret metadata: name: dockerhub-account annotations: build.knative.dev/docker-0: https://index.docker.io/v1/ type: kubernetes.io/basic-auth data: # 'echo -n \"username\" | base64' username: dXNlcm5hbWUK # 'echo -n \"password\" | base64' password: cGFzc3dvcmQK 例 3-2. kubectl apply kubectl apply -f knative-build-demo/secret.yaml 首先要注意的是，username 和 password 在传递给 Kubernetes 时都是 base64 编码的。还应注意到，使用 basic-auth 根据 Docker Hub 进行身份验证，这意味着将使用用户名和密码进行身份验证，而不是类似于 access token（访问令牌）的东西。此外，Knative 还附带了开箱即用的 ssh-auth，这允许使用 SSH 私钥从私有 Git 存储库中拉取代码。 除了将 Secret 命名为 dockerhub-account 之外，还对 Secret 进行了注解。Annotation（注解）是说明连接到特定主机时使用哪些凭据的一种方式。在例 3-3 中，定义了连接到 Docker Hub 时使用的基于身份的验证凭证集。 我的凭据安全吗？ 使用 base64 编码对凭证进行编码不是为了安全性，而是为了可靠地将这些字符串传输到 Kubernetes 。在后端，Kubernetes 提供了关于如何加密 Secret 的更多选项。有关加密 Secret 的详细资料，请参考 Kubernetes 文档。 一旦创建了名为 dockerhub-account 的 Secret ，接下来必须创建要运行应用程序的 Service Account ，以便它能够访问 Kubernetes 中的凭据。配置很简单，如例 3-3 所示。 Example 3-3. knative-build-demo/serviceaccount.yaml apiVersion: v1 kind: ServiceAccount metadata: name: build-bot secrets: - name: dockerhub-account 例中创建了一个名为 build-bot 的 ServiceAccount ，允许它访问 dockerhub-account Secret 。在例中当推送容器镜像时，Knative 使用这些凭证对 Docker Hub 进行身份验证。 Build Resource（构建资源） 首先从 Hello World 应用程序开始。这是一个简单的 Go 应用程序，它监听端口 8080 并以 “Hello from Knative!” 作为 HTTP GET 请求的响应。代码如例 3-4 所示。 例 3-4. knative-helloworld/app.go package main import ( \"fmt\" \"log\" \"net/http\" ) func handlePost(rw http.ResponseWriter, req *http.Request) { fmt.Fprintf(rw, \"%s\", \"Hello from Knative!\") } func main() { log.Print(\"Starting server on port 8080...\") http.HandleFunc(\"/\", handlePost) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 然后编写一个 Dockerfile 来构建代码和容器，如例 3-5 所示。 例 3-5. knative-helloworld/Dockerfile FROM golang ADD . /knative-build-demo WORKDIR /knative-build-demo RUN go build ENTRYPOINT ./knative-build-demo EXPOSE 8080 在前面的第 2 章中，您已经在本地构建了容器并手动将其推送到容器镜像库。然而，Knative 为在 Kubernetes 集群中使用 Build 来完成这些步骤提供了一种更好的方式。与 Configuration （配置）和 Route（路由）一样，Build 也可以简单地作为 Kubernetes 自定义资源（CRD）来通过 YAML 定义的方式实现。在深入研究每个组件之前，先来看一看例 3-6 ，看看 Build 的配置是什么样的。 例 3-6. knative-build-demo/service.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: knative-build-demo namespace: default spec: runLatest: configuration: build: serviceAccountName: build-bot source: git: url: https://github.com/gswk/knative-helloworld.git revision: master template: name: kaniko arguments: - name: IMAGE value: docker.io/gswk/knative-build-demo:latest revisionTemplate: spec: container: image: docker.io/gswk/knative-build-demo:latest 在构建步骤之前，您还会在源代码部分看到源码存放位置的定义。目前，Knative 发布了三个代码源选项： git：Git 仓库，可以选择使用参数来定义分支、标记或提交 SHA 。 gcs：位于谷歌云存储中的存档文件。 自定义：任意容器镜像仓库。这允许用户编写自己的源代码，只要将源代码放在 /workspace 目录中即可。 只需要安装一个额外的组件，即 Build Template（构建模板）。将会在 “Build template” 一节中向你更深入地介绍这些内容，但是现在，先将继续使用在 YAML 中定义的方式，在本例中是 Kaniko Build Template 如例 3-7 所示。 例 3-7. 安装 Kaniko Build Template kubectl apply -f https:// raw.githubusercontent.com/knative/build-templates/master/kaniko/kaniko.yaml 通过应用模板，可以像在 Serving 例中那样部署服务，配置如例 3-8 所示。 例 3-8. 部署应用程序 kubectl apply -f knative-build-demo/service.yaml 然后，该构建将运行以下步骤： 从 gswk/knative-helloworld 的 GitHub repo 中拉取代码。 在 repo 中使用 Kaniko Build Template（下一节将详细描述）。 使用前面设置的 “build-bot” Service Account 将容器推送到 DockerHub 的 gswk/knative-build-demo 仓库。 使用新构建的容器部署应用程序。 Build Template（构建模板） 在例 3-6 中，使用了一个 Build Template ，但还从未真正讲解过 Build Template 是什么和怎样运行的。简单来说，Build Template 是可共享的、封装的、参数化的构建步骤集合。目前，Knative 已经支持多个 Build Template ，包括： Kaniko 在运行的容器中构建容器镜像，而不依赖于运行 Docker daemon 。 Jib 为 Java 应用程序构建容器镜像。 Buildpack 自动检测应用程序的运行时，并建立一个容器镜像使用 Cloud Foundry Buildpack。 虽然这并不是可用模板的完整列表，但是可以轻松地集成 Knative 社区开发的新模板。安装 Build Template 就像应用 YAML 文件安装 Service（服务）、Route（路由）或 Build configuration（构建配置）一样简单： kubectl apply -f https://raw.githubusercontent.com/knative/ build-templates/master/kaniko/kaniko.yaml 然后可以像其他配置一样应用例 3-6 来部署应用程序，同时向它发送请求，就像在第 2 章中所做的那样： kubectl apply -f knative-build-demo/service.yml $ curl -H \"Host: knative-build-demo.default.example.com\" http://$KNATIVE_INGRESS 在例 3-9 中继续使用 Kaniko 作为参考来进一步观察 Build Template 。 例 3-9. https://github.com/knative/build-templates/blob/master/kaniko/kaniko.yaml apiVersion: build.knative.dev/v1alpha1 kind: BuildTemplate metadata: name: kaniko spec: parameters: - name: IMAGE description: The name of the image to push - name: DOCKERFILE description: Path to the Dockerfile to build. default: /workspace/Dockerfile steps: - name: build-and-push image: gcr.io/kaniko-project/executor args: - --dockerfile=${DOCKERFILE} - --destination=${IMAGE} Build Template 的 steps 部分具有与 Build 完全相同的语法，只是使用命名变量进行模板化。实际上，除了用变量替换路径之外，steps 部分看起来非常类似于例 3-6 的模板部分。parameters 部分在 Build Template 所期望的参数周围放置了一些结构。Kaniko Build Template 需要一个定义在何处推送容器镜像的 IMAGE 参数，但是有一个可选的 DOCKERFILE 参数，如果没有定义该参数，则提供一个默认值。 结论 Knative 中的 Build 在部署应用程序时去掉了许多手动步骤。此外，Build Template 提供了一些构建代码和去掉手动管理组件数量的好方法。随着时间的推移，可能会有越来越多的 Build Template 被构建并与 Knative 社区分享，这可能是最值得关注的事情之一。 我们已经花了很多时间来构建和运行应用程序，但是 Serverless 的最大承诺之一是，它可以使您的服务轻松地连接到事件源。在下一章中，将研究 Knative 的 Eventing（事件）组件以及开箱即用的所有可用事件源。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-10-21 15:27:52 "},"eventing.html":{"url":"eventing.html","title":"Eventing（事件）","summary":"这是本书第4章的内容，主要介绍事件的源、通道和订阅三大概念。","keywords":"","body":"Eventing（事件） 到目前为止，向应用程序发送基本的 HTTP 请求是一种有效使用 Knative 函数的方式。然而，无服务器的松耦合特性同时也适用于事件驱动架构。也就是说，可能在文件上传到 FTP 服务器时我们需要调用一个函数；又或者，任何时间我们在进行一笔物品销售时需要调用一个函数来处理支付和库存更新的操作。与其让我们的应用程序或函数考虑监听事件的逻辑，不如当那些被关注的事件发生时，让 Knative 去处理并通知我们。 自己实现这些功能则需要做很多工作并要编写实现特定功能的代码。幸运的是，Knative 提供了一个抽象层使消费事件变得更容易。Knative 直接提供了一个“事件”，而不需要你写特定的代码来选择消息代理。当事件发生时应用程序根本无需关心它来自哪里或发到哪去，就只需要知道事件发生了这么简单。为实现这一目标，Knative 引入了三个新的概念：Source（源）、Channel（通道）和 Subscription（订阅）。 Sources（源） 如你所料，Source 是事件的来源，它是我们定义事件在何处生成以及如何将事件传递给关注对象的方式。例如，Knative 团队开发了许多开箱即用的源。举几个例子： GCP PubSub 订阅谷歌云消息发布订阅服务中的主题并监听消息。 Kubernetes Event Kubernetes 集群中发生的所有事件的反馈。 GitHub 监视 GitHub 存储库中的事件，例如版本的拉取，推送和创建发布等。 Container Source 如果你需要创建自己的事件源，Knative 还有一个抽象叫容器源，允许你轻松创建自定义的事件源，并打包为容器。详细内容请阅读“构建自定义事件源”章节。 这个列表只是整个事件的一部分，但整个事件清单在不断的快速增长。你可以在 Knative 事件文档中的 Knative 生态系统部分查看事件源的当前列表。 让我们来看一个使用 Kubernetes 事件源将日志输出到标准输出的简单案例。我们将部署一个运行在 8080 端口上用于监听 POST 请求并输出请求结果的函数，如例 4-1 所示。 例4-1: knative-eventhing-demo/app.go package main import ( \"fmt\" \"io/ioutil\" \"log\" \"net/http\" ) func handlePost(rw http.ResponseWriter, req *http.Request) { defer req.Body.Close() body, _ := ioutil.ReadAll(req.Body) fmt.Fprintf(rw, \"%s\", body) log.Printf(\"%s\", body) } func main() { log.Print(\"Starting server on port 8080...\") http.HandleFunc(\"/\", handlePost) log.Fatal(http.ListenAndServe(\":8080\", nil)) } 任何人都可以像我们一样部署此服务，如例 4-2 所示。 例4-2： knative-eventing-demo/service.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: knative-eventing-demo spec: runLatest: configuration: revisionTemplate: spec: container: image: docker.io/gswk/knative-eventing-demo:latest $ kubectl apply -f knative-eventing-demo/service.yaml 如果不出意外的话，我们甚至可以像前两章节那样向该服务发送下面的请求： $ curl $SERVICE_IP -H \"Host: knative-eventing-demo.default.example.com\" -XPOST -d \"Hello, Eventing\" > hello, Eventing 接下来，我们可以设置一个 Kubernetes 事件源。在配置和身份认证方面，不同的事件源则有不同的要求。例如，GCP PubSub 源则要求向谷歌云平台进行身份请求验证，对于 Kubernetes 事件源，则需要创建一个可以读取到 Kubernetes 集群内发生的事件的 ServiceAccount。与第三章中做法一样，我们在 YAML 中定义了这个服务帐户并将其应用到我们的集群，如例 4-3 所示。 例4-3: knative-eventing-demo/serviceaccount.yaml apiVersion: v1 kind: ServiceAccount metadata: name: events-sa namespace: default --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: creationTimestamp: null name: event-watcher rules: - apiGroups: - \"\" resources: - events verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: creationTimestamp: null name: k8s-ra-event-watcher roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: event-watcher subjects: - kind: ServiceAccount name: events-sa namespace: default $ kubectl apply -f knative-eventing-demo/serviceaccount.yaml 当 events-sa ServiceAccount 创建好后，剩下就是定义事件的实际来源，在我们的演示案例中它就是一个 Kubernetes 事件源实例。该实例将以一个特定的配置运行，在该演示案例中则是一个预定义的 ServiceAccount，具体配置如例 4-4 所示。 例4-4: knative-eventing-demo/source.yaml apiVersion: sources.eventing.knative.dev/v1alpha1 kind: KubernetesEventSource metadata: name: k8sevents spec: namespace: default serviceAccountName: events-sa sink: apiVersion: eventing.knative.dev/v1alpha1 kind: Channel name: knative-eventing-demo-channel 其中大部分都相当简单，我们将创建的对象类型定义为 KubernetesEventSource，简称为 k8sevents，并传递一些特定实例的配置，例如我们应该运行的 Namespace 和使用的 ServiceAccount。你可能已经注意到了一个新的东西，即接收器（sink）配置。 接收器是定义我们想把事件发送到的目的地和 Kubernetes 的对象参考的一种方法。或者更简单地说，就是一种在 Kubernetes 中寻址到另一个预定义对象的方法。在 Knative 中和事件源做对接的通常会是一个服务（如果我们想要将事件直接发送到在 Knative 上运行的应用程序），或者是一个尚未引入的组件——通道。 Channel（通道） 现在我们已经为事件定义了一个源，则需要某个地方来接收它们。虽然你可以将事件直接发送到服务，这也就意味着你可以自己处理重试的逻辑和队列。当一个事件发送到你的服务并且它恰好关闭时会发生什么？如果要将相同的事件发送到多个服务，又该怎么办？为了回答这些问题，Knative 引入了通道的概念。 通道处理缓冲和持久性，即使该服务已被关闭时也确保将事件传递到其预期的服务。另外，通道是我们代码和底层消息传递解决方案之间的一个抽象层。这意味着可以像 Kafka 和 RabbitMQ 一样在某些服务之间进行消息交换，但在这两种情况下我们都不需要编写特定的实现代码。继续我们的演示案例，我们将设置一个用于发送所有事件的通道，如例 4-5 所示。你会注意到此通道与我们在示例 4-4 中的事件源中定义的接收器很像。 例4-5: knative-eventing-demo/channel.yaml apiVersion: eventing.knative.dev/v1alpha1 kind: Channel metadata: name: knative-eventing-demo-channel spec: provisioner: apiVersion: eventing.knative.dev/v1alpha1 kind: ClusterChannelProvisioner name: in-memory-channel $ kubectl apply -f knative-eventing-demo/channel.yaml 在这里，我们创建了一个 knative-eventing-demo-channel 的通道，并定义我们想要创建的通道类型，在该演示案例中则是一个 in-memory-channel（内存通道）。正如前面所述，Knative 事件的一个重要目标是它完全从底层基础架构中抽象出来，这意味着支持可插入通道的消息服务。这是通过 ClusterChannelProvisioner（集群通道提供者）一种用于定义 Knative 应如何与消息传递服务进行通信的模式来实现的。演示案列使用了内存通道配置程序，但 Knative 实际上也提供了一些选项来支持通道服务： in-memory-channel 完全在 Kubernetes 集群的内存中进行处理，不依赖于独立运行的服务来传递事件。非常适合开发，但不建议用于生产环境。 GCP PubSub 仅使用谷歌云消息发布订阅托管服务来传递信息但需要访问谷歌云平台帐户权限。 Kafka 将事件发送到正在运行的 Apache Kafka 集群，这是一个开源的集群分布式流媒体平台，具有出色的消息队列功能。 NATS 将事件发送到正在运行的 NATS 集群，这是一个高性能的开源消息系统，可以以各种模式和配置传递和使用消息。 尽管有了这些选项，但还有一个问题：我们如何实现从通道将事件发送到我们的服务？ Subscriptions（订阅） 我们将事件源发送到通道，并准备好开始处理它们的服务，但目前我们没有办法获取从通道发送到服务的事件。Knative 允许我们给这种情况定义订阅功能。订阅是通道和服务之间的纽带，指示 Knative 如何在整个系统中管理我们的事件。图 4-1 展示了如何使用订阅将事件路由到多个应用程序的示例。 图4-1. 事件源可以将事件发送到通道，以便多个服务可以同时接收它们，或者它们可以直接发送到一个服务 Knative 中的服务不了解或不关心事件和请求是如何获取的。它可以是来自入口网关的 HTTP 请求，也可以是从通道发送来的事件。无论何种方式，服务仅接收 HTTP 请求。这是 Knative 中一个重要的解耦方式，它确保我们将代码编写到架构中，而不是在底层。我们创建订阅，通道向服务发送事件。正如示例 4-6 所示，该定义仅使用了两个引用，一个引用 Channel（通道），另一个引用 Service（服务）。 例4-6: knative-eventing-demo/subscription.yaml apiVersion: eventing.knative.dev/v1alpha1 kind: Subscription metadata: name: knative-eventing-demo-subscription spec: channel: apiVersion: eventing.knative.dev/v1alpha1 kind: Channel name: knative-eventing-demo-channel subscriber: ref: apiVersion: serving.knative.dev/v1alpha1 kind: Service name: knative-eventing-demo 到此，我们已经准备好了所有的通道，以便可以将事件发送到应用程序上。Kubernetes 会记录集群中发生的事件，事件源会将其发送到通道再发送到我们的服务，这要归功于我们定义的订阅功能。如果我们查看服务中的日志，可立即看到这些事件，如例 4-7 所示。 例4-7: 从服务中检查日志 $ kubectl get pods -l app=knative-eventing-demo-00001 -o name pod/knative-eventing-demo-00001-deployment-764c8ccdf8-8w782 $ kubectl logs knative-eventing-demo-00001-deployment-f4c794667-mcrcv -c user-container 2019/01/04 22:46:41 Starting server on port 8080... 2019/01/04 22:46:44 {\"metadata\":{\"name\":\"knative-eventing-demo-00001.15761326c1edda18\",\"namespace\":\"default\"...[Truncated for brevity] 总结 这些构建块为帮助实现丰富和健全的事件驱动架构铺平了道路，但这仅仅是个开始。我们将在“构建自定义事件源”章节中使用容器源创建自定义源，还将在第 7 章中展示事件。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-10-21 16:47:10 "},"installing-knative.html":{"url":"installing-knative.html","title":"Knative 安装","summary":"本书第五章节，讲述了 Knative 的安装。","keywords":"","body":"Knative 安装 在开始使用 Knative 构建和托管工作负载前，您需要安装它。您还应该运行一些命令来验证它是否正常运行并按预期工作。本章将介绍从 Mac 或 Linux shell 安装和验证 Knative 的必要步骤。 建立一个 Knative 集群 首先，您需要已经有一个 Kubernetes 集群。 Knative 要求 Kubernetes 的版本在1.11以上。您必须在集群上启用 MutatingAdmissionWebhook admission controller。为了简单，您可以在本地机器上使用 Minikube 或者在云上运行集群。 为什么我们需要安装 Istio 迄今为止，我们还没讨论过 Istio，但是它作为安装的一部分出现了。Istio 是什么？Knative 为什么需要它？ Istio 是一个服务网络。它在 Kubernetes 之上提供了很多特性，包括流量管理、网络策略执行和可观察性。我们不认为 Istio 是 Knative 的组件，而是它的依赖项之一，就像 Kubernetes 一样。所以 Knative 最终使用 Istio 运行在 Kubernetes 集群之上。 本报告的目的不是详细说明 Istio 的内部工作。在这一章中，我们将介绍 Istio 与 Knative 一起使用时要用到的关于 Istio 的所有知识。如果您想了解更多，可以从 What is Istio? 以及 Istio documentation 开始。 须知 建立 Kubernetes 集群有许多选择。决定使用哪种工具取决于您的需求和提供者对特定工具集的熟悉程度。在 GitHub 中参考 Knative’s installation documentation 以获得特定提供者的指令。 在您的本地机器上，请确保您已经安装了 kubectl v1.11或更高版本。将上下文设置指向 Knative 设置的集群。您将使用 kubectl 以 YAML 文件的形式应用于所有的 crd。 集群建立之后，使用以下两个命令设置 Istio： kubectl apply --filename https://storage.googleapis.com/knative-releases/serving/latest/istio.yaml kubectl label namespace default istio-injection=enabled 第一个命令将所有必需的 Istio 对象导入集群。第二个命令在 default 命名空间中启用 Istio 自动注入。这可以确保 Istio 在 default 命名空间中为每个 Pod 创建时自动注入边车（sidecar）。（您会注意到所有 Pod 至少都有两个容器。一个是用户的容器；一个是 istio-proxy。) Knative 依赖于 Istio 组件。使用以下命令验证 Istio 安装，直到所有 Pod 显示为运行或完成： kubectl get pods -n istio-system --watch 现在您已经使用 Istio 运行了集群，可以开始安装 Knative。使用 kubectl 命令安装 Knative 的核心组件 Serving 和 Build。YAML 声明文件可以从 Google Storage 或 GitHub 获取。您可以使用特定的版本或使用最新的 release 版本。下面的命令将从 Google Storage 中获取最新的版本： kubectl apply --filename https://storage.googleapis.com/knative-releases/serving/latest/release.yaml kubectl apply --filename https://storage.googleapis.com/knative-releases/build/latest/release.yaml 再次验证这些对象是否正确导入。使用以下命令监视它们，直到所有 Pod 显示为运行： kubectl get pods --namespace knative-serving --watch kubectl get pods --namespace knative-build --watch 小贴士： 轻量安装 如果您正在本地机器上安装 Knative 或刚刚开始安装，您可能希望在不使用内置监控（在 monitoring 命名空间下）组件的情况下安装 Knative。在这种情况下，您可以使用以下命令来安装服务： kubectl apply --filename https://storage.googleapis.com/knative-releases/serving/latest/release-no-mon.yaml 这避免了在 monitoring 命名空间中安装任何组件。想要获取更多信息，请看 第 7 章指标和日志。 Serving 和 Build 安装完成并运行后，按照类似的步骤启动 Eventing 模块： kubectl apply --filename https://storage.googleapis.com/knative-releases/eventing/latest/release.yaml kubectl get pods --namespace knative-eventing --watch 最后，您可以选择安装您需要的 Build 模板。这一步与第三章中的步骤完全相同。下面是安装 Kaniko 和 Buildpacks 模板的命令： kubectl apply -f https://raw.githubusercontent.com/knative/build-templates/master/kaniko/kaniko.yaml kubectl apply -f https://raw.githubusercontent.com/knative/build-templates/master/buildpack/buildpack.yaml 须知 如果您计划使用 Build 模块将源代码打包到镜像中，您需要一个容器仓库来推送。在安装 Knative 的同时，考虑设置对所选容器仓库的访问。容器仓库您可以选择 Docker Hub 或谷歌容器仓库这样的公共托管方式，或者您也可以设置自己的私有仓库。有关访问和将镜像推送到仓库的更多信息，请参阅第4章中的 Build 组件。 您可以使用 kubectl get buildtemplates 命令验证 Build 模板是否已成功安装。这将返回 default 命名空间中安装的所有构建模板的列表： $ kubectl get knative NAME AGE buildpack 1m kaniko 1m 删除 Knative 对象 您可能希望在添加某些 Knative 组件之后删除它们。可以使用 kubectl delete 命令从集群中删除任何 Knative 对象。正如您使用 kubectl apply 引用 YAML 文件一样，您也可以使用 kubectl delete 执行相同的操作： kubectl delete -f https://raw.githubusercontent.com/knative/build-templates/master/kaniko/kaniko.yaml Kubernetes 集群已启动。Istio 已经安装。已添加了 Serving 、 Build 和 Eventing 组件。您可能已经添加了一两个 Build 模板。您几乎已经准备好开始使用 Knative 了。剩下的只需要获取一些关于如何在网络上访问它的信息。 安装方法选择 本章中的步骤展示了如何使用本地的 kubectl apply 命令分别安装 Knative 组件。然而，一些构建在 Knative 之上的无服务器框架也可能包含安装系统的快捷方式。例如， riff 提供了一个在 Kubernetes 集群上安装和运行 Knative 的一行程序： riff system install 这需要 riff CLI 和 Kubernetes 集群已经建立且 kubectl 已经指向正确的上下文。 访问 Knative 集群 设置好 Knative 集群之后，就可以将应用程序部署到 Knative 上了。但您需要知道如何使用它们。它们如何暴露在集群中？ Knative 在 istio-system 命名空间中使用 LoadBalancer 方式。使用以下命令获取外部 IP 地址，列名： EXTERNAL-IP $ kubectl get svc istio-ingressgateway --namespace istio-system NAME TYPE CLUSTER-IP EXTERNAL-IP istio-ingressgateway LoadBalancer 10.23.247.74 35.203.155.229 正如您将在第 6 章中看到的，这个 IP 地址加上正确的 HTTP HOST 头就可以向集群上的应用程序发起请求。为了方便使用，可以把外部 IP 地址设置为 KNATIVE_INGRESS 这个环境变量： $ export KNATIVE_INGRESS=$(kubectl get svc istio-ingressgateway --namespace istio-system --output 'jsonpath={.status.loadBalancer.ingress[0].ip}') $ echo $KNATIVE_INGRESS 35.203.155.229 现在，使用与我们在第 2 章中看到的类似的 curl 命令，我们可以使用这个环境变量向 Knative 环境中的服务发出请求： curl -H \"Host: my-knative-service-name.default.example.com\" http://$KNATIVE_INGRESS 不支持 Load Balancer？ 如果您的 Kubernetes 实例不支持 load balancer（比如： Minikube），命令会略有不同因为 EXTERNAL-IP 会显示为 。使用以下命令返回节点的 IP 和端口： $ export KNATIVE_INGRESS=$(kubectl get node --output 'jsonpath={.items[0].status.addresses[0].address}'):$(kubectl get svc istio-ingressgateway> --namespace istio-system --output 'jsonpath={.spec.ports[?(@.port==80)].nodePort}') $ echo $KNATIVE_INGRESS 10.10.0.10:32380 结论 现在已经设置好了一切，可以将应用程序部署到 Knative 了。在第 6 章，您将看到一些不同的示例。您还将了解通过设置静态 IP、自定义域名以及 DNS 配置来公开集群的更健壮的方式。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-10-21 17:44:19 "},"using-knative.html":{"url":"using-knative.html","title":"Knative 使用","summary":"本章讲述了使用 knative 的高级用例。","keywords":"","body":"使用 Knative 通过前面的章节已经扎实掌握 Knative 的组件了，现在是时候开始研究一些更高级的主题了。Serving 为如何路由流量提供了相当大的灵活性，还有其他的构建模板使构建应用程序变得容易。只需几行代码即可轻松制作我们自己的事件源。在本章中，我们将深入研究这些功能，让我们的代码在 Knative 上更容易地运行。 创建和运行 Knative Services 第 2 章 介绍了 Knative Service 的概念。 回想一下，Knative 中的 Service 是单个配置和路由集合的组合。在 Knative 和 Kubernetes 体系内，它最终是 Pod 中的 0 个或多个容器以及其他使您的应用程序可寻址的组件。所有这些都由具有强大流量策略选项的路由层支持。 无论您将工作负载视为应用程序，容器还是流程，它都将在 Knative 中作为服务运行。这为处理许多场景提供了灵活性，具体取决于构成软件的资产。本节提供了 Knative 为您构建和部署软件提供的另一种选择。 使用 Cloud Foundry Buildpack 构建模板 您在第 3 章中看到，Kaniko 构建模板允许您使用 Dockerfile 构建容器镜像。此方法要求您负责编写和维护 Dockerfile。如果您希望完全消除管理容器的负担，您可能希望使用不同的构建模板。Buildpack 构建模板负责基础镜像，并引入构建和运行应用程序所需的所有依赖项。 Cloud Foundry 是一种开源平台即服务（PaaS），它利用 buildpack 来简化开发和运维。在 Cloud Foundry 中，buildpacks 将检查您的源代码，以自动确定要下载的运行时和依赖项，构建代码以及运行应用程序。例如，使用 Ruby 应用程序，buildpack 将下载 Ruby 运行时并在 Gemfile 上运行 bundle install 以下载所有必需的依赖项。Java buildpack 将为您的应用程序下载 JVM 和任何所需的依赖项。通过使用 Buildpack Build Template，这个模型在 Knative 中也可用。 与 Kaniko Build Template 一样，您必须将 Buildpack Build Template CRD 应用到环境： kubectl apply -f https://raw.githubusercontent.com/knative/build-templates/master/buildpack/buildpack.yaml Knative Services 仅依赖 Serving 组件。Build 模块不需要在 Knative 中部署和运行 Service。那你为什么要在你的服务中嵌入 Build 呢？你怎么知道在特定情况下这是一个好主意？ 考虑您的软件开发生命周期的过程是非常重要的。您是否有一个现有的，成熟的构建流水线来生成容器镜像并将它们推送到 registry 仓库？如果是这样，您可能不需要 Knative Build 为您工作。如果没有，在 Knative Service 中定义 Build 方法可能会使事情变得更容易。 具体使用哪个构建模板还需要依据您希望如何打包代码和依赖项而定。对于使用既定流程管理 Dockerfile 的 Docker 重度使用者而言，Kaniko 是一个很好的选择。而 Cloud Foundry 的用户或开发者们只喜欢编写代码并且不太关心基础设施那么 Buildpack Build Template 会是更好的选择。经验丰富的 Java 用户可能已经熟悉使用 Jib 来构建 Java 容器，这使得它成为正确的选择。无论您的过程如何，Knative 都会提供一些不错的抽象，同时允许您选择最适合您的方法。 在 Knative 中，Buildpack 构建模板将使用 Cloud Foundry 的相同构建包，包括自动检测要应用于代码的构建包。如果您参考例6-1 你会看到很像 Kaniko Buildpack，你只能定义代码的位置以及推送容器镜像的位置。最大的区别是没必要提供 Dockerfile。 相反，构建模板知道如何为此应用程序构建容器。 例6-1 knative-buildpack-demo/service.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: knative-buildpack-demo namespace: default spec: runLatest: configuration: build: serviceAccountName: build-bot source: git: url: https://github.com/gswk/knative-buildpack-demo.git revision: master template: name: buildpack arguments: - name: IMAGE value: docker.io/gswk/knative-buildpack-demo:latest revisionTemplate: spec: container: image: docker.io/gswk/knative-buildpack-demo:latest 在此创建和运行 Knative Services ,除了代码和容器注册表的路由之外，与示例3-6中的 Kaniko 构建的唯一不同之处在于模板的名称已从 kaniko 更改为 buildpack。 例如，git 存储库是 Node.js 应用程序 hello.js，以及定义应用程序的依赖关系和元数据的 package.json 文件。在这种情况下，Build Template 将下载 Node 运行时和 npm 可执行文件，运行npm install，最后构建容器并将其推送到 Docker Hub。 您可能发现已应用了大量 YAML 文件，并且不确定是否已创建所有的 Knative 对象。有一个命令方便你确认这些问题，命令如下所示： kubectl get knative -n {NAMESPACE} 返回给定命名空间中所有的 Knative 对象列表。 kubectl get knative --all-namespaces 返回集群上存在的所有 Knative 对象。 部署注意事项 Knative 还提供不同的部署方法，具体取决于最适合您服务的方案。我们在第 2 章展示了一个 Knative 路由如何可以用来将流量发送到特定的修订。以下部分将详细介绍 Knative Routes 如何实现蓝绿部署和增量部署。 零停机部署 在第 2 章中，您了解了如何将单个路由指向多个修订版以及如何实现零停机部署。由于修订是不可变的，并且可以同时运行多个版本，因此可以在为旧版本提供流量时调出新版本。然后，一旦准备好将流量引导到新版本，请立即更新路由切换。这有时被称为蓝绿部署，蓝和绿代表不同的版本。 例6-2 重新审视了 第 2 章中的 Route 定义。 例6-2所有流量都将路由到 00001 修订版 apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-helloworld namespace: default spec: traffic: - revisionName: knative-routing-demo-00001 name: v1 percent: 100 如第 2 章所述，您可以在 knative-helloworld.default.example.com 和 v1.knative-helloworld.default.example.com 上访问修订版 knative-routing-demo-00001。让我们考虑一个场景，你已经在代码中添加了一些新功能或修复了一些错误，然后构建并将其推送到 Knative。这导致一个名为 knative-routing-demo-00002 的新版本。 但是，在开始向应用程序发送生产流量之前，我们希望确保它正常运行。 在例6-3中有一个名为 v2 的新路由，但没有路由到它的生产流量。 例6-3 我们的新版本 apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-helloworld namespace: default spec: traffic: - revisionName: knative-routing-demo-00001 name: v1 percent: 100 - revisionName: knative-routing-demo-00002 name: v2 percent: 0 这些修订版已命名为 v1 和 v2（尽管您可以选择任何名称，例如蓝和绿）。这意味着您可以在 v2.knative-helloworld.default 访问新版本。example.com 路由仍然只会将流量发送到 00001 修订版。在更改流量之前，请访问新版本并对其进行测试以确保它已准备好用于生产流量。当新版本准备好接收生产流量时，请再次更新路由，如例6-4 所示。 例6-4 将所有实时流量发送到我们的新版本 apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-helloworld namespace: default spec: traffic: - revisionName: knative-routing-demo-00002 name: v2 percent: 100 应用后，新的配置流量将立即路由到 00002 版本而不会出现任何停机。发现代码中的新错误并需要回滚？可以很容易的再次更新 Route 配置以指向原始版本。因为修订版是不可变的，而 Knative 会存储过去的版本 yaml 配置，您可以随时路由它们。这包括对特定容器镜像、配置以及与修订版相关的任何构建信息的引用。 增量部署 Knative Routes 支持的另一种部署模式是逐步部署新版本的代码。这可以用于 AB 测试，或者在为每个用户释放功能之前将功能推广到用户子集。在 Knative 中，这是通过使用基于百分比的路由来实现的。 虽然类似于蓝绿部署示例 6-4，你可以在例 6-5 中看到 而不是路由0% 对于 v2的流量，我们在 v1和 v2上均匀分配负载。您也可以选择使用80-20之类的其他拆分，甚至可以拆分三个修订版。每个修订版仍可通过指定的子域访问，但用户流量将按百分比值进行拆分。 例6-5 部分负载路由 apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-helloworld namespace: default spec: traffic: - revisionName: knative-routing-demo-00001 name: v1 percent: 50 - revisionName: knative-routing-demo-00002 name: v2 percent: 50 自定义域 到目前为止所涵盖的每个示例都使用了通用示例域。 这不是用于生产应用程序的 URL。不仅如此，还不可能路由到 example.com。值得庆幸的是，Knative 提供了使用自定义域的选项。开箱即用，Knative 为每个 Route 使用{route}.{namespace}.{domain}方案，并为 example.com 使用默认域。 使用 knative-custom-domain 示例作为示例6-6中显示的起始位置，默认情况下它接收 knative-custom-domain.default.example.com 的 Route。 例6-6 knative-custom-domain/configuration.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Configuration metadata: name: knative-custom-domain namespace: default spec: revisionTemplate: spec: container: image: docker.io/gswk/knative-helloworld imagePullPolicy: Always 由于我们已将此定义为配置而非服务，因此我们还需要为应用程序定义路由，如例6-7。将这两种配置分开将为我们提供更高级别的定制，例如我们在讨论零停机部署时所说的那些定制，但也将让我们更新我们的域和路由，而无需重新部署整个应用程序。 例6-7 knative-custom-domain/route.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-custom-domain namespace: default spec: traffic: - revisionName: knative-custom-domain-00001 name: v1 percent: 100 正如预期的那样，这将创建一个服务并在 knative-custom-domain.default.example.com 上创建一个 Route。现在来看看如何将默认 URL 方案中的域名从 example.com 更改为您实际可以路由到的域名。此示例使用本书的网站 dev.gswkbook.com 的子域。这可以通过更新配置域 ConfigMap 轻松完成，该配置域由 Knative 的默认配置，如例 6-8 所示。 例6-8 knative-custom-domain/domain.yaml apiVersion: v1 kind: ConfigMap metadata: name: config-domain namespace: knative-serving data: dev.gswkbook.com: \"\" Knative 最终应该协调对域的更改。重新创建 Route 将加快进程： $ kubectl delete -f route.yaml $ kubectl apply -f route.yaml 看一下更改后的路由，您会看到它现在已获得 knative-custom-domain.default.dev 的更新网址。 gswkbook.com。如果您的入口网关可公开访问（即，在 Google 的 GKE 或类似的托管 Kubernetes 产品上设置），您可以为 *.dev.gswkbook.com 创建一个通配符 DNS 条目， 以便路由到您的 Knative 安装并访问您的服务和功能直接通过互联网，如例 6-9 所示。 例6-9 $ kubectl get route knative-custom-domain -o yaml apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: ... status: ... domain: knative-custom-domain.default.dev.gswkbook.com ... traffic: - name: v1 percent: 100 revisionName: knative-custom-domain-00001 您可能还希望为不同的部署设置不同的域。例如，默认情况下，您可能希望将所有内容部署到开发域，然后在测试后将其转发到生产域。Knative 提供了一种简单的启用此功能的机制，允许您定义多个域并标记路由以确定它们所在的域。让我们再次更新 config-domain ConfigMap，设置另一个用于生产的域名 *.prod.gswkbook.com，如图所示例6-10 例6-10 knative-custom-domain/domain.yaml apiVersion: v1 kind: ConfigMap metadata: name: config-domain namespace: knative-serving data: prod.gswkbook.com: | selector: environment: prod dev.gswkbook.com: \"\" 在例 6-11 中，我们已经定义了具有 environment: prod 标签的 Route 将被放置在 prod.gswkbook.com 域上，否则它将默认放置在 dev.gswkbook.com 域中。您需要做的就是将应用程序移动到这个新域，然后在配置的元数据部分中使用这个新标签更新您的 Route。 例6-11 knative-custom-domain/route-label.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Route metadata: name: knative-custom-domain namespace: default labels: environment: prod spec: traffic: - revisionName: knative-custom-domain-00001 name: v1 percent: 100 应用后，您的路由会自动更新，并且假设您的 DNS 配置正确，可以立即在新域中访问。您可以通过在检索 Route CRD 时确保域条目匹配来验证这一点，如例 6-12 所示。 kubectl describe route knative-custom-domain 例6-12 knative-custom-domain 路由 description Name: knative-custom-domain Namespace: default ... Kind: Route Metadata: ... Spec: ... Status: ... Domain: knative-custom-domain.default.prod.gswkbook.com Domain Internal: knative-custom-domain.default.svc.cluster.local ... 构建自定义事件源 假设我们希望应用程序从没有事件源的源接收事件。例如，我们可能希望定期检查文件服务器是否有新文件，或者请求 URL 来监视更改。将这些代码组合在一起很容易，但是运行它的最佳方法是什么？像其他 Knative 应用程序一样运行它是没有意义的，因为它需要永久运行，但是如果我们在 Knative 之外运行它，那么我们就需要手动管理和配置的新组件。 Knative 通过使用 ContainerSource 轻松创建自己的事件源来解决这个问题。使用此事件源，我们提供 Knative 容器，Knative 将为容器提供 POST 事件的 URL。只要满足这几个简单的要求，我们就可以用我们喜欢的任何语言编写事件源： 它可以打包成一个容器，并有一个 ENTRYPOINT 定义，所以它知道如何运行我们的代码。 2.它希望接收一个 --sink CLI 标志，Knative 将提供一个指向已配置目标的 URL。 让我们看看它是如何工作的，通过构建一个事件源，它将在给定的时间间隔内发出当前时间，称为时间事件源。首先，让我们看看事件源的代码例 6-13。 例6-13 time-event-source/app.rb require 'optparse' require 'net/http' require 'uri' # 默认 CLI 选项（如果省略） options = { :sink => \"http://localhost:8080\", :interval => 1 } # 解析 CLI 标志 opt_parser = OptionParser.new do |opt| opt.on(\"-s\", \"--sink SINK\", \"Location to send events\") do |sink| options[:sink] = sink end opt.on(\"-i\", \"--interval INTERVAL\", \"Poll frequency\") do |interval| options[:interval] = interval.to_i end end opt_parser.parse! # 按给定间隔发送当前时间到给定的接收器 uri = URI.parse(options[:sink]) header = {'Content-Type': 'text/plain'} loop do http = Net::HTTP.new(uri.host, uri.port) request = Net::HTTP::Post.new(uri.request_uri, header) request.body = Time.now.to_s response = http.request(request) sleep options[:interval] end 解析 CLI 标志后，这个 Ruby 应用程序进入一个死循环，不断地将当前时间 POST 到由 --sink 标志提供的 URL，然后根据 --interval 标志提供的秒数休眠。由于这需要打包为容器，我们还有一个用于构建它的 Dockerfile，如例 6-14 所示。 例6-14 time-event-source/Dockerfile FROM ruby:2.5.3-alpine3.8 ADD . /time-event-source WORKDIR /time-event-source ENTRYPOINT [\"ruby\", \"app.rb\"] 这里并不奇怪。我们使用官方 Ruby 镜像作为基础，添加我们的代码，并定义如何运行我们的代码。我们可以构建我们的容器并将其发送到 Docker Hub。在我们运行事件源之前，我们需要一个发送事件的地方。我们已经开始构建一个非常简单的 Knative 应用程序，它记录了所有它收到的 HTTP POST 的主体请求。 例6-15 time-event-source/service.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: logger spec: runLatest: configuration: revisionTemplate: spec: container: image: docker.io/gswk/logger:latest 我们将应用在例 6-15 中所示的 YAML ，命名为 logger 并部署它。 kubectl apply -f service.yaml 剩下的就是让我们的事件源在 Knative 中运行。YAML 与其他事件源的概述相同，我们在例 6-16 中可以看到。 例6-16 time-event-source/source.yaml apiVersion: sources.eventing.knative.dev/v1alpha1 kind: ContainerSource metadata: labels: controller-tools.k8s.io: \"1.0\" name: time-eventsource spec: image: docker.io/gswk/time-event-source:latest args: - '--interval=1' sink: apiVersion: serving.knative.dev/v1alpha1 kind: Service name: logger 这里有几个需要注意的点。首先，我们在 image 参数中为 Knative 提供了 Event Source 容器的位置，就像我们部署 Service 时一样。其次，我们在 args 数组中提供了 --interval 标志，但我们省略了 --sink 标志。这是因为 Knative 将查看我们提供的接收器（在本例中为我们的日志服务），查找 URL 到该资源，并自动将其提供给我们的事件源。 这意味着，在 Event Source 容器的内部，最后我们的代码将使用类似于以下内容的命令调用： ruby app.rb --interval=1 --sink=http://logger.default.example.com 我们将使用我们期望的通常的 kubectl apply 命令来部署它： kubectl apply -f source.yaml 很快，我们会看到一个新的 Pod 被创建出来，但重要的区别在于它将永久运行而不会降低到零个。我们可以查看记录器务的日志，以验证我们的事件是否符合预期，如例 6-17 所示。 例6-17 从我们的记录器中检索日志服务 $ kubectl get pods -l app = logger-00001 -o name pod/logger-00001-deployment-57446ffb59-vzg97 $ kubectl logs logger-00001-deployment-57446ffb59-vzg97 -c user-container 2018/12/26 21:12:59 Starting server on port 8080... [Wed 26 Dec 2018 21:13:00 UTC] 2018-12-26 21:13:00 +0000 [Wed 26 Dec 2018 21:13:01 UTC] 2018-12-26 21:13:01 +0000 [Wed 26 Dec 2018 21:13:02 UTC] 2018-12-26 21:13:02 +0000 [Wed 26 Dec 2018 21:13:03 UTC] 2018-12-26 21:13:03 +0000 [Wed 26 Dec 2018 21:13:04 UTC] 2018-12-26 21:13:04 +0000 [Wed 26 Dec 2018 21:13:05 UTC] 2018-12-26 21:13:05 +0000 这种简单的抽象使我们能够快速轻松地提供自己的事件源。不仅如此，而且与构建模板非常相似，您可以设想如何轻松地与 Knative 社区共享这些事件源，因为它们很容易插入到您的环境中。我们还将在第七章 中查看另一个自定义事件源 结论 到目前为止，我们的内容已经涵盖了相当多的用例，从初级的到高级的，但我们只是自己看了这些概念，一次展示一个功能。如果你像我们一样，真正有用的是将它们全部放在一个现实世界的例子中，观察每个组件如何相互作用。在下一章中，我们将做到这一点并构建一个利用我们所学知识的应用程序！ Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-04-26 11:53:09 "},"putting-it-all-together.html":{"url":"putting-it-all-together.html","title":"演练","summary":"通过一个可视化地展示世界各地的地震活动的演练，将前几章所学知识进行了一个串联。存在问题: 原文中 bit.ly 链接无法打开，前端容器镜像也无法访问到。","keywords":"","body":"演练 让我们把所学的知识运用起来来创造一个项目吧！我们进行一个演练，它利用了前面所学到的许多知识，并通过使用美国地质勘探局 (USGS) 地震数据源的数据提供了一个服务，以可视化地展示世界各地的地震活动。您可以在 GitHub 存储库 gswk/earthquakedemo 上找到我们将要介绍的代码。 架构 在深入研究代码之前，让我们先看看应用程序的体系架构，如 图7-1 所示。我们在这里构建三个重要的东西:事件源、服务和前端。 图中 Knative 内部的每一个组件都代表着我们将利用目前所学的知识来构建的内容，包括使用 Kaniko 构建模板的服务和用于轮询数据的自定义事件源: USGS 事件源 我们将构建一个自定义的 ContainerSource 事件源，它将在给定的时间间隔轮询 USGS 提供的数据。为预构建的容器镜像打包。 图 7-1 应用程序的体系结构。来自于 USGS 的地震数据源作为事件进入我们的事件源，这将触发我们的 GeoCoder 服务来持久化事件。我们的前台也将使用我们的 Geocoder 服务来查询最近的事件。 Geocoder 服务 这将为事件源提供 POST 事件的节点，并使用提供的坐标查找地址。它还将作为前端用来查询和检索最近的事件的节点。我们将使用 Build 服务来构建容器镜像，与运行在 Kubernetes 上的 Postgres 数据库通信。 前端 一个可以可视化最近的地震活动的轻量级的、持续运行的前端。 我们可以使用 Helm 在 Kubernetes 集群上轻松地搭建起 Postgres 数据库，Helm 是一个可以轻松地在 Kubernetes 上打包和共享应用程序包的工具。关于如何在您的 Kubernetes 集群上启动和运行的介绍，请务必参考 Helm 的文档。如果您运行在 Minikube 或没有任何特定的权限要求的 Kubernetes 集群上，那么您可以使用以下简单的命令来设置 Helm: $ helm init 对于像谷歌的 GCP 这样具有更深层安全配置的集群，请参考 Helm Quickstart 指南。接下来我们可以设置一个 Postgres 数据库并且传递一些配置参数以使设置更容易： $ helm install --name geocodedb --set postgresqlPassword=devPass,postgresqlDatabase =geocode stable/postgresql 这将在我们的 Kubernetes 集群中创建一个 Postgres 数据库，将用户密码设置为 devPass ，并创建一个名为 geocode 的数据库。我们已经将 Postgres 服务器命名为 geocodedb ，这意味着在 Kubernetes 集群中，我们可以通过 geocodedb-postgresql.default.svc.cluster.local 访问该服务器。现在让我们来深入了解代码吧! Geocoder 服务 如应用程序体系结构图所示，我们的事件源和前端都将向 Geocoder 服务发送请求，后者将与 Postgres 数据库通信。这将我们的服务置于应用程序的中心位置。对我们服务的 HTTP POST 请求将会在数据库中记录事件，而 GET 请求将检索过去24小时内发生的事件。让我们来看一下 示例 7-1 中我们服务的代码。 示例 7-1 geocoder/app.rb require 'geocoder' require 'json' require 'pg' require 'sinatra' set :bind, '0.0.0.0' # DB connection credentials are passed via environment # variables DB_HOST = ENV[\"DB_HOST\"] || 'localhost' DB_DATABASE = ENV[\"DB_DATABASE\"] || 'geocode' DB_USER = ENV[\"DB_USER\"] || 'postgres' DB_PASS = ENV[\"DB_PASS\"] || 'password' # Connect to the database and create table if it doesn't exist conn = PG.connect( dbname: DB_DATABASE, host: DB_HOST, password: DB_PASS, user: DB_USER) conn.exec \"CREATE TABLE IF NOT EXISTS events ( id varchar(20) NOT NULL PRIMARY KEY, timestamp timestamp, lat double precision, lon double precision, mag real, address text );\" # Store an event post '/' do d = JSON.parse(request.body.read.to_s) address = coords_to_address(d[\"lat\"], d[\"long\"]) id = d[\"id\"] conn.prepare(\"insert_#{id}\", 'INSERT INTO events VALUES ($1, $2, $3, $4, $5, $6)') conn.exec_prepared(\"insert_#{id}\", [d[\"id\"], d[\"time\"], d[\"lat\"], d[\"long\"], d[\"mag\"], address.to_json]) end # Get all events from the last 24 hours get '/' do select_statement = \"select * from events where timestamp > 'now'::timestamp - '24 hours'::interval;\" results = conn.exec(select_statement) jResults = [] results.each do |row| jResults \"*\" return jResults.to_json end # Get the address from a given set of coordinates def coords_to_address(lat, lon) coords = [lat, lon] results = Geocoder.search(coords) a = results.first address = { address: a.address, house_number: a.house_number, street: a.street, county: a.county, city: a.city, state: a.state, state_code: a.state_code, postal_code: a.postal_code, country: a.country, country_code: a.country_code, coordinates: a.coordinates } return address end 我们将使用 Knative 为我们构建容器镜像，将连接到 Postgres 数据库所需的信息传递给它，并运行我们的服务。我们可以在 示例7-2 中看到这是如何设置的。 示例 7-2. earthquake-demo/geocoder-service.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: geocoder namespace: default spec: runLatest: configuration: build: serviceAccountName: build-bot source: git: url: https://github.com/gswk/geocoder.git revision: master template: name: kaniko arguments: - name: IMAGE value: docker.io/gswk/geocoder revisionTemplate: spec: container: image: docker.io/gswk/geocoder env: - name: DB_HOST value: \"geocodedb-postgresql.default.svc.cluster.local\" - name: DB_DATABASE value: \"geocode\" - name: DB_USER value: \"postgres\" - name: DB_PASS value: \"devPass\" kubectl apply -f earthquake-demo/geocoder-service.yaml 因为我们已经通过环境变量传递了所有连接信息给我们的 Postgres 数据库，这是我们的服务运行需要的所有信息。接下来，我们将获取事件源并运行它，以便我们可以开始向新部署的服务发送事件。 USGS 事件源 我们的事件源将负责在指定的时间间隔内轮询 USGS 地震活动的数据，解析它，并将其发送到我们定义的接收器。由于我们需要轮询数据，并且没有由 USGS 将其推送给我们的可能，因此它非常适合使用 ContainerSource 编写自定义事件源。 在设置事件源之前，还需要一个事件发送的通道。虽然我们可以直接将事件从事件源发送到我们的服务，但如果我们希望将来能够将事件发送到另一个服务，这将给我们带来一些灵活性。我们只需要一个简单的通道，我们将在 示例 7-3 中定义它。 示例 7-3. earthquake-demo/channel.yaml apiVersion: eventing.knative.dev/v1alpha1 kind: Channel metadata: name: geocode-channel spec: provisioner: apiVersion: eventing.knative.dev/v1alpha1 kind: ClusterChannelProvisioner name: in-memory-channel kubectl apply -f earthquake-demo/channel.yaml 正如我们在第6章中构建自定义事件源一样，我们的这个事件源也是由一个脚本构成，在本例中是一个 ruby 脚本，它接受两个命令行标志位: --sink 和 --interval。让我们在 示例7-4中看看它。 示例 7-4. usgs-event-source/usgs-event-source.rb require 'date' require \"httparty\" require 'json' require 'logger' require 'optimist' $stdout.sync = true @logger = Logger.new(STDOUT) @logger.level = Logger::DEBUG # Poll the USGS feed for real-time earthquake readings def pull_hourly_earthquake(lastTime, sink) # Get all detected earthquakes in the last hour url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/\" \\ + \"summary/all_hour.geojson\" response = HTTParty.get(url) j = JSON.parse(response.body) # Keep track of latest recorded event, reporting all # if none have been tracked so far cycleLastTime = lastTime # Parse each reading and emit new ones as events j[\"features\"].each do |f| time = f[\"properties\"][\"time\"] if time > lastTime msg = { time: DateTime.strptime(time.to_s,'%Q'), id: f[\"id\"], mag: f[\"properties\"][\"mag\"], lat: f[\"geometry\"][\"coordinates\"][1], long: f[\"geometry\"][\"coordinates\"][0] } publish_event(msg, sink) end # Keep track of latest reading if time > cycleLastTime cycleLastTime = time end end lastTime = cycleLastTime return lastTime end # POST event to provided sink def publish_event(message, sink) @logger.info(\"Sending #{message[:id]} to #{sink}\") puts message.to_json r = HTTParty.post(sink, :headers => {'Content-Type'=>'text/plain'}, :body => message.to_json) if r.code != 200 @logger.error(\"Error! #{r}\") end end # Parse CLI flags opts = Optimist::options do banner 10 opt :sink, \"Sink to send events\", :default => \"http://localhost:8080\" end # Begin polling USGS data lastTime = 0 @logger.info(\"Polling every #{opts[:interval]} seconds\") while true do @logger.debug(\"Polling . . .\") lastTime = pull_hourly_earthquake(lastTime, opts[:sink]) sleep(opts[:interval]) end 像前面一样，Knative 在作为 ContainerSource 事件源运行时将处理 --sink 标志位。我们还提供了一个额外的标记 --interval，我们将定义这个标记，因为我们编写的代码将允许用户定义自己的轮询间隔。脚本被打包为 Docker 镜像并上传到 Dockerhub 上的 gswk/usgs-event-source 下。剩下的就是创建 示例 7-5 中所示的事件源的 yaml，并创建订阅，以便将事件从通道发送到 示例 7-6 中所示的服务。 示例 7-5. earthquake-demo/usgs-event-source.yaml apiVersion: sources.eventing.knative.dev/v1alpha1 kind: ContainerSource metadata: labels: controller-tools.k8s.io: \"1.0\" name: usgs-event-source spec: image: docker.io/gswk/usgs-event-source:latest args: - \"--interval=10\" sink: apiVersion: serving.knative.dev/v1alpha1 kind: Service name: geocoder $ kubectl apply -f earthquake-demo/subscription.yaml 一旦我们应用这个 yaml，事件源将启动一个持续运行的容器，该容器将轮询事件并将它们发送到我们创建的通道中。另外，我们需要将 Geocoder 服务连接到通道中。 示例 7-6. earthquake-demo/subscription.yaml apiVersion: eventing.knative.dev/v1alpha1 kind: Subscription metadata: name: geocode-subscription spec: channel: apiVersion: eventing.knative.dev/v1alpha1 kind: Channel name: geocode-channel subscriber: ref: apiVersion: serving.knative.dev/v1alpha1 kind: Service name: geocoder $ kubectl apply -f earthquake-demo/subscription.yaml 创建了订阅之后，我们已经将所有内容连接起来，以便将事件通过自定义事件源带到环境中，然后将它们发送到服务中，服务将把它们持久化到 Postgres 数据库中。我们还有最后一个要部署的部分，那就是我们的前端，用来可视化所有东西。 前端 最后，我们需要把我们收集的所有数据一起放在前端来进行可视化。我们创建了一个简单的网站，并将其打包在一个容器镜像中，该容器镜像将使用 Nginx 提供服务。当页面加载时，它将调用 Geocoder 服务，返回一个地震事件的数组，包括坐标和震级，并在地图上显示它们。我们还将把它设置为 Knative 服务，这样我们就可以免费获得简易的路由和度量。同样，我们将像其他 Knative 服务一样编写一个 yaml，并使用 Kaniko 构建模板，如 示例 7-7 所示。 示例 7-7. earthquake-demo/frontend/frontend-service.yaml apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: earthquake-demo namespace: default spec: runLatest: configuration: build: serviceAccountName: build-bot source: git: url: https://github.com/gswk/earthquake-demo-frontend.git revision: master template: name: kaniko arguments: - name: IMAGE value: docker.io/gswk/earthquake-demo-frontend revisionTemplate: spec: container: image: docker.io/gswk/earthquake-demo-frontend env: - name: EVENTS_API value: \"http://geocoder.default.svc.cluster.local\" $ kubectl apply -f earthquake-demo/frontend-service.yaml 我们定义 EVENTS_API 环境变量，前端将使用该变量来了解 Geocoder 服务的位置。最后这一部分就绪后，我们就可以启动并运行整个系统了!我们的应用程序如 图 7-2 所示。 图 7-2 我们的应用程序启动起来了 当请求进入我们的前端应用程序时，它将从 Geocoder 服务中提取事件，当新事件进入时，它们将被我们的自定义事件源接收。此外，Knative 还提供了一些额外的工具，通过内置的日志记录、度量和跟踪功能，帮助您保持应用程序和服务的正常运行。 度量及日志纪录 任何在生产环境中运行过代码的人都知道我们的故事还没有结束。因为编写了代码和部署了应用程序，我们就需要对管理和运维负责。正确地了解代码如何处理日志及度量是该运维流程的一部分，幸运的是 Knative 附带了许多工具来提供这些信息。更好的是，它的大部分功能已经自动绑定到您的代码中，而不需要您做任何特殊的事情。 让我们从深入研究 Geocoder 服务的日志开始，这个功能由 Kibana 提供，Kibana 是我们设置 Knative 的服务组件时安装的。在我们访问任何东西之前，我们需要在我们的 Kubernetes 集群中设置一个代理，只需一个命令就可以轻松完成: $ kubectl proxy 这将为访问整个 Kubernetes 集群中打开一个代理，并可以在我们机器的8001端口上访问它。这也包括 Kibana，我们可以通过 http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana 访问它。 我们需要提供一个索引模板，我们可以简单地使用 * 和 timestamp_millis 的时间过滤器。最后，如果我们转到 Kibana 的 Discover 选项卡，我们将看到系统中的每个日志！让我们看一下通过如下搜索方式发送到 Geocoder 服务的请求及其结果，如 图7-3 所示。 localEndpoint.serviceName = geocoder 图 7-3 展示我们的Geocoder服务日志的Kibana仪表板 那么，如果只想看粗略的度量标准呢？看看某些指标比如失败的请求和响应时间可以提供我们解决应用程序问题的线索，Knative 还通过与 Grafana 一起提供非常多的度量指标（从响应代码的分布到我们的服务使用了多少 CPU）来帮助我们解决这个问题。Knative 甚至包括一个仪表盘，用于可视化当前集群的使用情况，以帮助进行容量规划。在加载 Grafana 之前，我们需要使用以下命令将端口转发到 Kubernetes 集群: $ kubectl port-forward --namespace knative-monitoring $(kubectl get pods --namespace knative-monitoring --selector=app=grafana --output=jsonpath=\"{.items..metadata.name}\") 3000 一旦转发，我们可以通过 http://localhost:3000 访问仪表板。在 图7-4 中，我们可以看到发送到 Geocoder 服务的请求的图，看起来很好很健康! 图 7-4 对Geocoder服务的成功和失败请求对比的图表 最后，Knative 还附带了 Zipkin 来帮助跟踪我们的请求。当请求通过我们的 ingress 网关进入，并到达数据库时，通过一些简单的仪表化，我们可以很好地了解我们的应用程序内部情况。在按照前述设置好代理之后，我们可以通过 http://localhost:8001/api/v1/namespaces/istio-system/services/zipkin:9411/proxy/Zipkin 来访问 Zipkin。一旦进入，我们就可以通过它看到请求如何发送到我们的 Geocoder服务上的，如 图 7-5 和 图 7-6 所示。 图7-5 对一个到Geocoder服务请求的简单跟踪 图 7-6 我们的服务请求堆栈时间分解 结论 一个完整的带有我们自己定制的事件源的应用程序成功了！这在很大程度上总结了我们在本书中要学习的内容，但是 Knative 还可以提供更多。同时，Knative 也在不断地发展和完善。当您继续您的学习旅程时，还有很多资源值得关注，所以在我们结束之前，我们需要知道我们在第8章中还提供其他一些参考资料。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-05-05 10:49:06 "},"what-is-next.html":{"url":"what-is-next.html","title":"下一步","summary":"本章是全书的展望部分，用来说明 Knative 生态体系未来展望以及如何进行 Knative 学习。","keywords":"","body":"下一步 还有越来越多的的项目持续的加入到年轻的 Knative 生态系统。有些已经将其他现有的开源无服务器架构（serverless）的框架带到 Knative 上。例如，Kwsk 就是努力用 Knative 来代替大部分 Apache OpenWhisk 基础服务器组件。其他开源的无服务器架构项目专门针对 Knative 而构建，甚至帮助完善 Knative 上游体系。例如，riff 项目已经提供了一组工具来帮助简化构建函数（Function）和使用 Knative。本章将简要介绍使用 riff 项目团队的一些工具在 Knative 上构建和运行函数。 使用 riff 项目打包函数 通过第 2 章中的 Hello World 示例，可以看出将现存的镜像从容器仓库部署到 Knative 是非常容易的。第 3 章中的 Kaniko 示例以及示例 6-1 中的 Buildpack 方式演示了如何为 Knative 构建和部署简单的十二要素（12-factor）应用程序。到目前为止，这些例子都集中在作为软件单元的容器或应用程序之上。现在回想一下第 1 章中提及函数，试想将一个函数部署到 Knative 是什么样的？答案是它看起来几乎与容器和应用程序一样。是因为有了 Build 模块，Knative 可以将您的函数代码转换为容器，其方式与应用程序代码相似。 什么是函数（Function）? 应用程序由代码组成，函数也是如此。那么函数有什么特别之处呢？难道它不是一个应用程序吗？应用程序一般由从前端 UI 到后端数据库的许多组件以及其间的所有处理组成。相比之下，函数通常只是一小段代码，具有单一目的，可以快速和异步地运行。它通常也由事件触发，而不是由用户在请求/响应场景中直接调用。 回想一下第 6 章中的 Cloud Foundry Buildpacks 示例。例 6-1 中显示的 service.yaml 文件引用了一个完整的 Node.js Express 应用程序，该应用程序的功能是在给定端口上侦听 GET 请求然后返回 “Hello World” 信息。如果我们的程序是接受数字作为输入，返回该数字的平方作为结果的函数，而不是 Hello World 应用程序呢？此代码可能类似于我们在示例 8-1 中看到的内容。 Example 8-1. knative-function-app-demo/square-app.js const express = require('express'); const app = express(); app.post('/', function (req, res) { let body = ''; req.on('data', chunk => { body += chunk.toString(); }); req.on('end', () => { if (isNaN(body)) res.sendStatus(400); else { var square = body ** 2; res.send(square.toString()); } }); }); var port = 8080; app.listen(port, function () { console.log('Listening on port', port); }); 我们可以使用示例 6-1 中的相同 Buildpack 来构建此函数并将其部署到 Knative。又如例 8-2，它也是使用 Node.js 编写的一个函数，它不是一个完整的 Express 应用程序，而仅仅由一个函数组成，不包含任何其他 Node.js 模块。 Example 8-2. knative-function-demo/square.js module.exports = (x) => x ** 2 Knative 支持这一点，因为它具有 Build 模块提供的灵活性。为了构建和部署这样的代码到 Knative，需要一个自定义的构建模板将这个简单的仅含函数的代码转换为可运行的 Node.js 应用程序。例 8-2 中的代码使用了 function invokers 特别支持的编程模型，function invokers 是 riff 项目一部分的。 riff 是 Pivotal 的一个开源项目，构建于 Knative 之上，它提供了一些很棒的东西：用于安装 Knative 和管理在其上部署的函数的 CLI，以及使我们能够编写像例 8-2 中代码的 function invokers。这些 invokers 负责执行函数，例如我们见过的 Node.js 示例，或 Spring Cloud Functions，甚至是 Bash 脚本。与 Build 模板一样，invokers 也是开源的，并且随着 riff 项目的成熟，invokers 支持调用的函数种类会越来越多。请务必查看 https://project-riff.io 了解更多信息！ 拓展阅读 在继续学习的过程中，有大量围绕 Knative 构建相关的文档、示例以及演示可以供您阅读和参考。最好的当然是 GitHub 仓库中 Knative Docs，它不仅包含有关 Knative 的每一部分如何工作的详细说明，而且还有更多的演示和加入社区的链接，例如 Knative Slack 频道或邮件列表。 我们非常感谢你花时间在我们的这本书上，希望对你开始上手使用 Knative 有帮助。我们可以留给你的最好建议就是要勤写代码并开始构建一些东西，无论大小。通过犯错并学习如何解决问题来探索和学习，与他人分享你学到的东西！Knative 的社区非常年轻，但成长速度非常快，我们希望看到你成为它的一员。 Copyright © servicemesher.com 2017-2019 all right reserved，powered by Gitbook 最后更新于 2019-05-05 10:49:06 "}}